---
{"dg-publish":true,"permalink":"/systems/the-chinese-room-argument/","dgPassFrontmatter":true,"noteIcon":"3","created":"2023-11-14T21:08:39.467+05:30","updated":"2024-01-04T04:48:22.411+05:30"}
---

🧶 Tags:: #systems 
==2023-02-27 - 23:54==

The [[Resources/🌏 WIKIs/Chinese room\|Chinese room]] is a thought experiment presented by philosopher [[Resources/🤼‍♂️ People/John Searle\|John Searle]] in 1980 to critique the idea of strong artificial intelligence (AI) or the claim that a computer program can have a mind and understand language in the same way as a human being.

The thought experiment involves a person who does not understand Chinese locked in a room with a set of instructions written in English that enable him to correctly respond to Chinese symbols he receives through a slot in the door.

The person in the room follows the instructions to manipulate the symbols and generate appropriate responses, fooling the person outside the room into thinking that the person in the room understands Chinese.

Searle argues that although the person in the room is able to perform the tasks of a Chinese speaker, he does not understand Chinese. Similarly, he argues that a computer program that responds to symbols according to a set of rules does not actually understand the language it is processing, but is merely manipulating symbols according to algorithms.